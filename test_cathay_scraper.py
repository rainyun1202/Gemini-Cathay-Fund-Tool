# test_cathay_scraper.py
import requests
import pandas as pd
import logging
import urllib3
import sys
import os

# === è¨­å®šç’°å¢ƒ ===
current_path = os.getcwd()
if current_path not in sys.path:
    sys.path.append(current_path)

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# === æ¸¬è©¦åƒæ•¸ ===
TEST_FUND_ID = "00120001" 

def test_scraper_full_functionality():
    """
    æ¸¬è©¦ FundScraper çš„å®Œæ•´åŠŸèƒ½ (æ·¨å€¼ + é…æ¯)
    """
    print(f"\nğŸš€ [æ¸¬è©¦] æ­£åœ¨å‘¼å« FundScraper é€²è¡Œæ•´åˆæ¸¬è©¦...")
    
    try:
        from modules.scraper import FundScraper
        scraper = FundScraper()
        
        # 1. æ¸¬è©¦æ·¨å€¼
        print(f"â³ (1/2) æŠ“å–æ·¨å€¼ (Fund ID: {TEST_FUND_ID})...")
        df_nav = scraper.fetch_nav(TEST_FUND_ID)
        if df_nav is not None and not df_nav.empty:
            print(f"âœ… æ·¨å€¼æŠ“å–æˆåŠŸï¼å¤§å°: {df_nav.shape}")
            print(df_nav.head(2))
        else:
            print("âš ï¸ æ·¨å€¼å›å‚³ç‚ºç©º")

        # 2. æ¸¬è©¦é…æ¯ (æ–°å¢)
        print(f"\nâ³ (2/2) æŠ“å–é…æ¯ç´€éŒ„ (Fund ID: {TEST_FUND_ID})...")
        df_div = scraper.fetch_dividend(TEST_FUND_ID)
        
        if df_div is not None and not df_div.empty:
            print(f"âœ… é…æ¯æŠ“å–æˆåŠŸï¼å¤§å°: {df_div.shape}")
            print("ğŸ“Š é…æ¯è³‡æ–™é è¦½:")
            print(df_div.head(3))
            
            # é©—è­‰æ•¸å€¼è½‰æ›
            if 'ç•¶æœŸé…æ¯ç‡(%)' in df_div.columns:
                print(f"ğŸ§ æª¢æŸ¥æ•¸å€¼å‹æ…‹: {df_div['ç•¶æœŸé…æ¯ç‡(%)'].dtype}")
        else:
            print("âš ï¸ é…æ¯ç´€éŒ„ç‚ºç©º (å¯èƒ½æ˜¯ç´¯ç©å‹åŸºé‡‘æˆ–ç„¡è³‡æ–™)")
            
    except ImportError:
        print("âŒ ç„¡æ³•åŒ¯å…¥ modulesï¼Œè«‹ç¢ºä¿æª”æ¡ˆä½ç½®æ­£ç¢º")
    except Exception as e:
        print(f"âŒ åŸ·è¡ŒéŒ¯èª¤: {e}")

if __name__ == "__main__":
    test_scraper_full_functionality()