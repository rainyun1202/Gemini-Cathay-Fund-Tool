import streamlit as st
import requests
import pandas as pd
import urllib3
import logging
import io
import yfinance as yf
import plotly.express as px  # æ–°å¢ï¼šäº’å‹•å¼ç¹ªåœ–å¥—ä»¶
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Optional, Any

# === è¨­å®šå€ ===
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

st.set_page_config(page_title="å…¨çƒå¸‚å ´èˆ‡åŸºé‡‘åˆ†æ", layout="wide")

class Config:
    """å…¨åŸŸé…ç½®é¡åˆ¥"""
    # --- åœ‹æ³°åŸºé‡‘è¨­å®š ---
    API_URL = "https://www.cathaybk.com.tw/cathaybk/service/newwealth/fund/chartservice.asmx/GetFundNavChart"
    BASE_URL = "https://www.cathaybk.com.tw/cathaybk/personal/investment/fund/details/?fundid={}"
    USER_AGENT = "Mozilla/5.0"
    TIMEOUT = 10
    DEFAULT_DATE_FROM = "1900/01/01"
    
    DEFAULT_FUND_IDS_LIST = [
        "00580030", "00400013", "00060004", "00100045", "00010144", "00120001",
        "00040097", "10340003", "10350005", "00060003", "00400029", "00100046",
        "00010074", "0074B059", "0012C007", "0012C004", "0012C033", "0012C035",
        "0012C008", "00100118", "00400156", "00400104", "00040052", "10020058",
        "10110022", "0074B065", "00100058", "00580062", "10310016", "00100063",
        "00560011", "00400072"
    ]

    # --- Yahoo Finance å¸‚å ´æŒ‡æ•¸è¨­å®š ---
    MARKET_TICKERS = {
        "æ¯”ç‰¹å¹£ (BTC-USD)": "BTC-USD",
        "VIX ææ…ŒæŒ‡æ•¸": "^VIX",
        "ç¾åœ‹ 10 å¹´æœŸå…¬å‚µæ®–åˆ©ç‡": "^TNX",
        "ç¾å…ƒæŒ‡æ•¸ (DXY)": "DX-Y.NYB",
        "å¸ƒè˜­ç‰¹åŸæ²¹": "BZ=F",
        "é»ƒé‡‘æœŸè²¨": "GC=F",
        "ç¾…ç´  2000": "^RUT",
        "NASDAQ æŒ‡æ•¸": "^IXIC",
        "S&P 500": "^GSPC",
        "è²»åŸåŠå°é«”": "^SOX",
        "ä¸Šè­‰æŒ‡æ•¸": "000001.SS",
        "é¦™æ¸¯åœ‹ä¼æŒ‡æ•¸": "^HSCE"
    }


class FundScraper:
    """è² è²¬æŠ“å–åœ‹æ³°åŸºé‡‘"""
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({"User-Agent": Config.USER_AGENT})
        self.session.verify = False 

    def fetch_nav(self, fund_id: str) -> Optional[pd.DataFrame]:
        target_url = Config.BASE_URL.format(fund_id)
        payload = {"req": {"Keys": [fund_id], "From": Config.DEFAULT_DATE_FROM}}
        headers = {"Referer": target_url}

        try:
            resp = self.session.post(Config.API_URL, json=payload, headers=headers, timeout=Config.TIMEOUT)
            resp.raise_for_status()
            data_json = resp.json()
            if not data_json.get('Data'): return None
            
            fund_info = data_json['Data'][0]
            df = pd.DataFrame(fund_info['data'], columns=['timestamp', 'NAV'])
            df['æ—¥æœŸ'] = pd.to_datetime(df['timestamp'], unit='ms').dt.date
            df['åŸºé‡‘åç¨±'] = fund_info['name']
            df['URL'] = target_url
            return df[['æ—¥æœŸ', 'NAV', 'åŸºé‡‘åç¨±', 'URL']]
        except Exception as e:
            logger.error(f"åŸºé‡‘ {fund_id} å¤±æ•—: {e}")
            return None

    def fetch_all(self, fund_ids: List[str]) -> Dict[str, pd.DataFrame]:
        # æ³¨æ„ï¼šç‚ºäº†é…åˆ Cachingï¼Œé€™è£¡ç§»é™¤äº† progress_bar çš„åƒæ•¸å‚³é
        # å› ç‚ºå¿«å–å‡½æ•¸åœ¨èƒŒæ™¯åŸ·è¡Œæ™‚ç„¡æ³•æ›´æ–° UI å…ƒä»¶
        results = {}
        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_id = {executor.submit(self.fetch_nav, fid): fid for fid in fund_ids}
            for future in as_completed(future_to_id):
                fid = future_to_id[future]
                try:
                    df = future.result()
                    if df is not None: results[fid] = df
                except Exception: pass
        return results


class MarketScraper:
    """è² è²¬æŠ“å– Yahoo Finance å¸‚å ´æ•¸æ“š"""
    def fetch_history(self, name: str, ticker: str) -> Optional[pd.DataFrame]:
        try:
            stock = yf.Ticker(ticker)
            # ä½¿ç”¨ "max" æŠ“å–å®Œæ•´æ­·å²æ•¸æ“š
            hist = stock.history(period="max")
            
            if hist.empty: return None
            
            hist = hist.reset_index()
            hist['Date'] = hist['Date'].dt.date
            
            df = pd.DataFrame()
            df['æ—¥æœŸ'] = hist['Date']
            df['NAV'] = hist['Close']
            df['åŸºé‡‘åç¨±'] = name
            df['URL'] = f"https://finance.yahoo.com/quote/{ticker}"
            
            return df[['æ—¥æœŸ', 'NAV', 'åŸºé‡‘åç¨±', 'URL']]
        except Exception as e:
            logger.error(f"å¸‚å ´æŒ‡æ•¸ {name} å¤±æ•—: {e}")
            return None

    def fetch_all(self, market_dict: Dict[str, str]) -> Dict[str, pd.DataFrame]:
        results = {}
        for name, ticker in market_dict.items():
            df = self.fetch_history(name, ticker)
            if df is not None: results[name] = df
        return results


class FundAnalyzer:
    """è² è²¬è¨ˆç®—é‚è¼¯"""
    @staticmethod
    def analyze_single(df: pd.DataFrame) -> Dict[str, Any]:
        df = df.sort_values('æ—¥æœŸ')
        fund_name = df['åŸºé‡‘åç¨±'].iloc[0]
        url = df['URL'].iloc[0]
        latest = df.iloc[-1]
        
        hist_max_idx = df['NAV'].idxmax()
        hist_min_idx = df['NAV'].idxmin()

        one_year_ago = df['æ—¥æœŸ'].max() - timedelta(days=365)
        df_1y = df[df['æ—¥æœŸ'] >= one_year_ago]
        
        if df_1y.empty:
            max_1y, min_1y, max_1y_date, min_1y_date = None, None, None, None
        else:
            max_1y_idx = df_1y['NAV'].idxmax()
            min_1y_idx = df_1y['NAV'].idxmin()
            max_1y = df_1y.loc[max_1y_idx, 'NAV']
            max_1y_date = df_1y.loc[max_1y_idx, 'æ—¥æœŸ']
            min_1y = df_1y.loc[min_1y_idx, 'NAV']
            min_1y_date = df_1y.loc[min_1y_idx, 'æ—¥æœŸ']

        return {
            "åŸºé‡‘åç¨±": fund_name,
            "åŸºé‡‘é€£çµ": url,
            "æœ€æ–°åƒ¹æ ¼": latest['NAV'],
            "æœ€æ–°åƒ¹æ ¼æ—¥æœŸ": latest['æ—¥æœŸ'],
            "æ­·å²æœ€é«˜åƒ¹æ ¼": df.loc[hist_max_idx, 'NAV'],
            "æ­·å²æœ€é«˜åƒ¹æ ¼æ—¥æœŸ": df.loc[hist_max_idx, 'æ—¥æœŸ'],
            "æ­·å²æœ€ä½åƒ¹æ ¼": df.loc[hist_min_idx, 'NAV'],
            "æ­·å²æœ€ä½åƒ¹æ ¼æ—¥æœŸ": df.loc[hist_min_idx, 'æ—¥æœŸ'],
            "è¿‘ä¸€å¹´æœ€é«˜åƒ¹æ ¼": max_1y,
            "è¿‘ä¸€å¹´æœ€é«˜åƒ¹æ ¼æ—¥æœŸ": max_1y_date,
            "è¿‘ä¸€å¹´æœ€ä½åƒ¹æ ¼": min_1y,
            "è¿‘ä¸€å¹´æœ€ä½åƒ¹æ ¼æ—¥æœŸ": min_1y_date
        }

    @staticmethod
    def analyze_all(data_map: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        summary_list = []
        for df in data_map.values():
            summary_list.append(FundAnalyzer.analyze_single(df))
        return pd.DataFrame(summary_list)


class ExcelReport:
    """Excel ç”¢ç”Ÿå™¨"""
    @staticmethod
    def create_excel_bytes(summary_df: pd.DataFrame) -> bytes:
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            display_df = summary_df.drop(columns=['åŸºé‡‘é€£çµ'])
            display_df.to_excel(writer, index=False, header=False, sheet_name='Summary', startrow=1)

            workbook = writer.book
            worksheet = writer.sheets['Summary']
            
            ExcelReport._apply_styles(workbook, worksheet, display_df, summary_df)
            ExcelReport._set_columns_width(display_df, worksheet)
            
            worksheet.freeze_panes(1, 0)
        return output.getvalue()

    @staticmethod
    def _apply_styles(workbook, worksheet, display_df, original_df):
        base_font = 'Microsoft JhengHei'
        header_fmt = workbook.add_format({'bold': True, 'font_name': base_font, 'bg_color': '#DCE6F1', 'align': 'center', 'valign': 'vcenter', 'border': 1})
        text_fmt = workbook.add_format({'font_name': base_font, 'valign': 'top', 'border': 1})
        num_fmt = workbook.add_format({'font_name': base_font, 'valign': 'top', 'border': 1, 'num_format': '#,##0.00'}) 
        link_fmt = workbook.add_format({'font_color': 'blue', 'underline': 1, 'font_name': base_font, 'valign': 'top', 'border': 1})
        date_fmt = workbook.add_format({'num_format': 'yyyy-mm-dd', 'font_name': base_font, 'valign': 'top', 'border': 1})

        for col, val in enumerate(display_df.columns):
            worksheet.write(0, col, val, header_fmt)

        date_cols = [i for i, c in enumerate(display_df.columns) if 'æ—¥æœŸ' in str(c) or 'Date' in str(c)]
        
        for i in range(len(display_df)):
            name = display_df.iat[i, 0]
            url = original_df.iloc[i]['åŸºé‡‘é€£çµ']
            worksheet.write_url(i+1, 0, url, link_fmt, string=name)

            for j in range(1, len(display_df.columns)):
                val = display_df.iat[i, j]
                if j in date_cols and pd.notna(val):
                    if isinstance(val, (str, datetime, pd.Timestamp)): val = pd.to_datetime(val)
                    worksheet.write_datetime(i+1, j, val, date_fmt)
                elif isinstance(val, (int, float)):
                    worksheet.write_number(i+1, j, val, num_fmt)
                else:
                    worksheet.write(i+1, j, str(val), text_fmt)

    @staticmethod
    def _set_columns_width(df, worksheet):
        for i, col in enumerate(df.columns):
            max_len = max(
                df[col].astype(str).map(lambda x: len(x.encode('utf-8'))).max(),
                len(str(col).encode('utf-8'))
            )
            width = min(max(max_len * 0.9, 10), 50)
            worksheet.set_column(i, i, width)

# === ã€æ–°å¢ã€‘ å¿«å–è³‡æ–™è¼‰å…¥å‡½å¼ ===
@st.cache_data(ttl=3600, show_spinner="æ­£åœ¨è‡ªç¶²è·¯ä¸‹è¼‰æœ€æ–°æ•¸æ“š...")
def load_data_with_cache(target_markets: Dict[str, str], fund_ids: List[str]) -> Dict[str, pd.DataFrame]:
    """
    é€™å€‹å‡½å¼æœƒè¢« Streamlit å¿«å–ã€‚
    åªè¦è¼¸å…¥åƒæ•¸ (fund_ids, target_markets) æ²’è®Šï¼Œå°±æœƒç›´æ¥å›å‚³ä¸Šæ¬¡çš„çµæœï¼Œä¸æœƒé‡æ–°ä¸‹è¼‰ã€‚
    """
    all_data = {}
    
    # ä¸‹è¼‰å¸‚å ´è³‡æ–™
    if target_markets:
        market_scraper = MarketScraper()
        # æ³¨æ„ï¼šç‚ºäº† Cache ç©©å®šï¼Œé€™è£¡ä¸å‚³å…¥ progress bar
        market_data = market_scraper.fetch_all(target_markets)
        all_data.update(market_data)
        
    # ä¸‹è¼‰åŸºé‡‘è³‡æ–™
    if fund_ids:
        fund_scraper = FundScraper()
        fund_data = fund_scraper.fetch_all(fund_ids)
        all_data.update(fund_data)
        
    return all_data

# === ã€æ–°å¢ã€‘ ç¹ªåœ–é‚è¼¯å‡½å¼ ===
def plot_normalized_trends(all_data: Dict[str, pd.DataFrame], selected_assets: List[str]):
    """ç¹ªè£½æ­¸ä¸€åŒ– (ç´¯ç©å ±é…¬ç‡) æ¯”è¼ƒåœ–"""
    if not selected_assets:
        st.info("è«‹å¾ä¸Šæ–¹é¸å–®å‹¾é¸è‡³å°‘ä¸€é …è³‡ç”¢é€²è¡Œæ¯”è¼ƒã€‚")
        return

    plot_data = []
    
    for name in selected_assets:
        if name in all_data:
            df = all_data[name].copy()
            df = df.sort_values('æ—¥æœŸ')
            
            # éæ¿¾æ‰æ¥µç«¯èˆŠçš„è³‡æ–™ï¼Œé¿å…åœ–è¡¨æ‹‰å¤ªé•·ï¼Œé€™è£¡é è¨­å–æœ€è¿‘ 3 å¹´ (è‹¥ä¸è¶³å‰‡å…¨å–)
            start_date_limit = pd.to_datetime("today") - pd.DateOffset(years=3)
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ']) # ç¢ºä¿æ—¥æœŸæ ¼å¼
            df = df[df['æ—¥æœŸ'] >= start_date_limit]

            if not df.empty:
                # æ­¸ä¸€åŒ–é‚è¼¯ï¼š(ç•¶æ—¥åƒ¹æ ¼ / ç¬¬ä¸€å¤©åƒ¹æ ¼ - 1) * 100
                first_nav = df['NAV'].iloc[0]
                df['ç´¯ç©å ±é…¬ç‡(%)'] = ((df['NAV'] / first_nav) - 1) * 100
                df['è³‡ç”¢åç¨±'] = name
                plot_data.append(df[['æ—¥æœŸ', 'ç´¯ç©å ±é…¬ç‡(%)', 'è³‡ç”¢åç¨±']])
    
    if not plot_data:
        st.warning("é¸å–çš„è³‡ç”¢åœ¨è¿‘ä¸‰å¹´å…§ç„¡è¶³å¤ æ•¸æ“šå¯ä¾›ç¹ªåœ–ã€‚")
        return

    # åˆä½µæ‰€æœ‰è³‡æ–™
    final_df = pd.concat(plot_data)
    
    # ä½¿ç”¨ Plotly ç•«åœ–
    fig = px.line(
        final_df, 
        x="æ—¥æœŸ", 
        y="ç´¯ç©å ±é…¬ç‡(%)", 
        color="è³‡ç”¢åç¨±",
        title="è¿‘ä¸‰å¹´ç´¯ç©å ±é…¬ç‡æ¯”è¼ƒ (æ­¸ä¸€åŒ–)",
        hover_data={"æ—¥æœŸ": "|%Y-%m-%d"},
        height=500
    )
    
    # å„ªåŒ–åœ–è¡¨æ¨£å¼
    fig.update_layout(
        xaxis_title="",
        yaxis_title="ç´¯ç©å ±é…¬ç‡ (%)",
        hovermode="x unified", # æ»‘é¼ ç§»éå»é¡¯ç¤ºæ‰€æœ‰è³‡ç”¢æ•¸å€¼
        legend=dict(orientation="h", y=1.1) # åœ–ä¾‹æ”¾ä¸Šé¢
    )
    
    st.plotly_chart(fig, use_container_width=True)


def main():
    st.title("ğŸ“Š å…¨çƒå¸‚å ´èˆ‡åŸºé‡‘æ·¨å€¼æˆ°æƒ…å®¤")
    st.markdown("æ•´åˆ **åœ‹æ³°åŸºé‡‘** èˆ‡ **å…¨çƒé—œéµå¸‚å ´æŒ‡æ¨™** çš„è‡ªå‹•åŒ–åˆ†æå·¥å…·ã€‚")

    # === å´é‚Šæ¬„ä½ˆå±€ ===
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®šé¢æ¿")
        
        with st.expander("ğŸŒ å…¨çƒå¸‚å ´æŒ‡æ¨™", expanded=True):
            selected_markets = st.multiselect(
                "é¸æ“‡é—œæ³¨å¸‚å ´æŒ‡æ¨™",
                options=list(Config.MARKET_TICKERS.keys()),
                default=list(Config.MARKET_TICKERS.keys())
            )
            target_markets = {name: Config.MARKET_TICKERS[name] for name in selected_markets}

        with st.expander("ğŸ¦ åœ‹æ³°åŸºé‡‘æ¸…å–®", expanded=True):
            default_ids = ",\n".join(Config.DEFAULT_FUND_IDS_LIST)
            fund_input = st.text_area(
                "åŸºé‡‘ä»£è™Ÿ (æ¯è¡Œä¸€å€‹)", 
                value=default_ids, 
                height=300, 
                help="è«‹è¼¸å…¥åŸºé‡‘ä»£è™Ÿï¼Œå¤šç­†è«‹æ›è¡Œæˆ–ç”¨é€—è™Ÿåˆ†éš”"
            )
            fund_ids = [x.strip() for x in fund_input.replace("\n", ",").split(",") if x.strip()]

    # === ä¸»é‚è¼¯ä¿®æ”¹ï¼šä½¿ç”¨ session_state æˆ–ç›´æ¥åŸ·è¡Œ ===
    # é€™è£¡æˆ‘å€‘å°‡é‚è¼¯æ”¹ç‚ºï¼šä½¿ç”¨è€…èª¿æ•´å´é‚Šæ¬„ -> é»æ“ŠæŒ‰éˆ• -> è¼‰å…¥è³‡æ–™ (æœ‰å¿«å–) -> é¡¯ç¤º Tabs
    
    if st.button("ğŸš€ é–‹å§‹/æ›´æ–° åˆ†æ", type="primary"):
        st.session_state['has_run'] = True

    # æª¢æŸ¥æ˜¯å¦å·²ç¶“æŒ‰éæŒ‰éˆ• (è®“ç•«é¢åˆ·æ–°æ™‚ä¸æœƒæ¶ˆå¤±)
    if st.session_state.get('has_run'):
        
        # 1. è¼‰å…¥è³‡æ–™ (ä½¿ç”¨å¿«å–ï¼Œé€Ÿåº¦å¿«)
        # æ³¨æ„ï¼šæˆ‘å€‘ç§»é™¤äº†é€²åº¦æ¢ï¼Œæ”¹ç”¨ st.spinner (ç”±è£…é¥°å™¨è™•ç†)
        all_data = load_data_with_cache(target_markets, fund_ids)

        if not all_data:
            st.error("âŒ æœªå–å¾—ä»»ä½•è³‡æ–™ï¼Œè«‹æª¢æŸ¥ç¶²è·¯æˆ–ä»£è™Ÿã€‚")
            return

        # 2. å»ºç«‹åˆ†é  (Tabs)
        tab1, tab2 = st.tabs(["ğŸ“‹ å ±è¡¨ç¸½è¦½", "ğŸ“ˆ è¶¨å‹¢æ¯”è¼ƒ"])

        # === åˆ†é  1ï¼šåŸæœ¬çš„è¡¨æ ¼èˆ‡ Excel ä¸‹è¼‰ ===
        with tab1:
            summary_df = FundAnalyzer.analyze_all(all_data)
            st.success(f"âœ… å®Œæˆï¼å…±åˆ†æ {len(summary_df)} ç­†æ¨™çš„")
            st.dataframe(summary_df)

            excel_data = ExcelReport.create_excel_bytes(summary_df)
            file_name = f"Global_Market_Report_{datetime.now().strftime('%Y%m%d')}.xlsx"
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰å®Œæ•´ Excel å ±è¡¨",
                data=excel_data,
                file_name=file_name,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

        # === åˆ†é  2ï¼šè¦–è¦ºåŒ–åœ–è¡¨ (æ–°å¢åŠŸèƒ½) ===
        with tab2:
            st.subheader("ğŸ“ˆ è³‡ç”¢èµ°å‹¢ PK")
            st.caption("æ¯”è¼ƒä¸åŒè³‡ç”¢åœ¨ç›¸åŒæ™‚é–“å€é–“å…§çš„æ¼²è·Œå¹…è¡¨ç¾ (è¿‘ä¸‰å¹´ï¼Œèµ·é»æ­¸é›¶)")
            
            # è®“ä½¿ç”¨è€…é¸æ“‡è¦ç•«å“ªäº›åœ– (é è¨­å…¨é¸ï¼Œä½†å¦‚æœå¤ªå¤šæœƒå¾ˆäº‚ï¼Œå»ºè­°é¸å‰ 5 å€‹)
            all_assets_list = list(all_data.keys())
            chart_selection = st.multiselect(
                "é¸æ“‡è¦ç¹ªè£½çš„è³‡ç”¢:",
                options=all_assets_list,
                default=all_assets_list[:5] # é è¨­åªé¸å‰5å€‹é¿å…çœ¼èŠ±
            )
            
            plot_normalized_trends(all_data, chart_selection)

if __name__ == "__main__":
    main()