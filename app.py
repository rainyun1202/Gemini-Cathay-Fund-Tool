import streamlit as st
import requests
import pandas as pd
import numpy as np
import urllib3
import logging
import io
import yfinance as yf
import plotly.graph_objects as go
import plotly.express as px  # æ–°å¢ï¼šç”¨æ–¼ç¹ªè£½ç†±åŠ›åœ–
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Optional, Any, Tuple
from dateutil.relativedelta import relativedelta

# === 0. å…¨åŸŸç’°å¢ƒè¨­å®š ===
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

st.set_page_config(page_title="å…¨çƒå¸‚å ´èˆ‡åŸºé‡‘åˆ†ææˆ°æƒ…å®¤", layout="wide")

# ==========================================
# 1. é…ç½®èˆ‡å¸¸æ•¸ (Configuration)
# ==========================================
class Config:
    """å…¨åŸŸé…ç½®é¡åˆ¥ï¼šé›†ä¸­ç®¡ç†æ‰€æœ‰å¸¸æ•¸ã€API è¨­å®šèˆ‡é è¨­æ¸…å–®"""
    
    # --- åœ‹æ³°åŸºé‡‘ API è¨­å®š ---
    API_URL = "https://www.cathaybk.com.tw/cathaybk/service/newwealth/fund/chartservice.asmx/GetFundNavChart"
    BASE_URL = "https://www.cathaybk.com.tw/cathaybk/personal/investment/fund/details/?fundid={}"
    USER_AGENT = "Mozilla/5.0"
    TIMEOUT = 10
    DEFAULT_DATE_FROM = "1900/01/01"
    
    # --- é è¨­é—œæ³¨çš„åŸºé‡‘ä»£è™Ÿ ---
    DEFAULT_FUND_IDS_LIST = [
        "00580030", "00400013", "00060004", "00100045", "00010144", "00120001",
        "00040097", "10340003", "10350005", "00060003", "00400029", "00100046",
        "00010145", "00740020", "00120005", "00120018", "00120193", "00120002",
        "00120134", "00100118", "00400156", "00400104", "00040052", "10020058",
        "10110022", "0074B065", "00100058", "00580062", "10310016", "00100063",
        "00560011", "00400072"
    ]

    # --- å…¨çƒå¸‚å ´æŒ‡æ¨™ (Yahoo Finance Tickers) ---
    MARKET_TICKERS = {
        # ç¾è‚¡ ETF
        "Vanguard S&P 500 (VOO)": "VOO",
        "Invesco QQQ (QQQ)": "QQQ",
        "Vanguard Total Intl Stock (VXUS)": "VXUS",
        "Vanguard Total World Bond (BNDW)": "BNDW",
        "VanEck Uranium+Nuclear (NLR)": "NLR",
        # é—œéµæŒ‡æ•¸èˆ‡å•†å“
        "æ¯”ç‰¹å¹£ (BTC-USD)": "BTC-USD",
        "VIX ææ…ŒæŒ‡æ•¸": "^VIX",
        "ç¾åœ‹ 10 å¹´æœŸå…¬å‚µæ®–åˆ©ç‡": "^TNX",
        "ç¾å…ƒæŒ‡æ•¸ (DXY)": "DX-Y.NYB",
        "å¸ƒè˜­ç‰¹åŸæ²¹": "BZ=F",
        "é»ƒé‡‘æœŸè²¨": "GC=F",
        "ç¾…ç´  2000": "^RUT",
        "NASDAQ æŒ‡æ•¸": "^IXIC",
        "S&P 500": "^GSPC",
        "è²»åŸåŠå°é«”": "^SOX",
        "ä¸Šè­‰æŒ‡æ•¸": "000001.SS",
        "é¦™æ¸¯åœ‹ä¼æŒ‡æ•¸": "^HSCE"
    }

    # --- æ™‚é–“å€é–“é¸é … ---
    TIME_RANGES = {
        "è¿‘1æœˆ": relativedelta(months=1),
        "è¿‘3æœˆ": relativedelta(months=3),
        "è¿‘åŠå¹´": relativedelta(months=6),
        "è¿‘1å¹´": relativedelta(years=1),
        "è¿‘3å¹´": relativedelta(years=3),
        "è¿‘5å¹´": relativedelta(years=5),
        "è¿‘10å¹´": relativedelta(years=10),
    }

    @staticmethod
    def get_start_date(time_range_key: str) -> datetime:
        """æ ¹æ“šæ™‚é–“å€é–“ Key è¨ˆç®—èµ·å§‹æ—¥æœŸ"""
        delta = Config.TIME_RANGES.get(time_range_key, relativedelta(years=1))
        return datetime.now() - delta

# ==========================================
# 2. è³‡æ–™ç²å–å±¤ (Data Scraping Layer)
# ==========================================
class FundScraper:
    """è² è²¬æŠ“å–åœ‹æ³°åŸºé‡‘æ­·å²æ·¨å€¼"""
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({"User-Agent": Config.USER_AGENT})
        self.session.verify = False 

    def fetch_nav(self, fund_id: str) -> Optional[pd.DataFrame]:
        target_url = Config.BASE_URL.format(fund_id)
        payload = {"req": {"Keys": [fund_id], "From": Config.DEFAULT_DATE_FROM}}
        headers = {"Referer": target_url}

        try:
            resp = self.session.post(Config.API_URL, json=payload, headers=headers, timeout=Config.TIMEOUT)
            resp.raise_for_status()
            data_json = resp.json()
            if not data_json.get('Data'): return None
            
            fund_info = data_json['Data'][0]
            df = pd.DataFrame(fund_info['data'], columns=['timestamp', 'NAV'])
            df['æ—¥æœŸ'] = pd.to_datetime(df['timestamp'], unit='ms').dt.date
            df['åŸºé‡‘åç¨±'] = fund_info['name']
            df['URL'] = target_url
            return df[['æ—¥æœŸ', 'NAV', 'åŸºé‡‘åç¨±', 'URL']]
        except Exception as e:
            logger.error(f"åŸºé‡‘ {fund_id} å¤±æ•—: {e}")
            return None

    def fetch_all(self, fund_ids: List[str]) -> Dict[str, pd.DataFrame]:
        results = {}
        with ThreadPoolExecutor(max_workers=10) as executor:
            future_to_id = {executor.submit(self.fetch_nav, fid): fid for fid in fund_ids}
            for future in as_completed(future_to_id):
                fid = future_to_id[future]
                try:
                    df = future.result()
                    if df is not None: results[fid] = df
                except Exception: pass
        return results


class MarketScraper:
    """è² è²¬æŠ“å– Yahoo Finance å¸‚å ´æ•¸æ“š"""
    def fetch_history(self, name: str, ticker: str) -> Optional[pd.DataFrame]:
        try:
            stock = yf.Ticker(ticker)
            hist = stock.history(period="max")
            
            if hist.empty: return None
            
            hist = hist.reset_index()
            hist['Date'] = hist['Date'].dt.date
            
            df = pd.DataFrame()
            df['æ—¥æœŸ'] = hist['Date']
            df['NAV'] = hist['Close']
            df['åŸºé‡‘åç¨±'] = name
            df['URL'] = f"https://finance.yahoo.com/quote/{ticker}"
            
            return df[['æ—¥æœŸ', 'NAV', 'åŸºé‡‘åç¨±', 'URL']]
        except Exception as e:
            logger.error(f"å¸‚å ´æŒ‡æ•¸ {name} å¤±æ•—: {e}")
            return None

    def fetch_all(self, market_dict: Dict[str, str]) -> Dict[str, pd.DataFrame]:
        results = {}
        for name, ticker in market_dict.items():
            df = self.fetch_history(name, ticker)
            if df is not None: results[name] = df
        return results

# ==========================================
# 3. è³‡æ–™è™•ç†èˆ‡åˆ†æå±¤ (Data Analysis Layer)
# ==========================================
class FundAnalyzer:
    """è² è²¬è¨ˆç®—å„é …æŒ‡æ¨™ã€å ±é…¬ç‡èˆ‡é¢¨éšªæ•¸æ“š"""
    
    @staticmethod
    def analyze_single(df: pd.DataFrame) -> Dict[str, Any]:
        """è¨ˆç®—å–®ä¸€åŸºé‡‘çš„åŸºç¤çµ±è¨ˆæ•¸æ“š (ç”¨æ–¼å ±è¡¨ç¸½è¦½)"""
        df = df.sort_values('æ—¥æœŸ')
        fund_name = df['åŸºé‡‘åç¨±'].iloc[0]
        url = df['URL'].iloc[0]
        latest_nav = df['NAV'].iloc[-1]
        
        # æ­·å²æ¥µå€¼
        hist_max, hist_min = df['NAV'].max(), df['NAV'].min()
        hist_max_date = df.loc[df['NAV'].idxmax(), 'æ—¥æœŸ']
        hist_min_date = df.loc[df['NAV'].idxmin(), 'æ—¥æœŸ']

        # è¿‘ä¸€å¹´æ•¸æ“š
        one_year_ago = df['æ—¥æœŸ'].max() - timedelta(days=365)
        df_1y = df[df['æ—¥æœŸ'] >= one_year_ago]
        
        if df_1y.empty:
            max_1y, min_1y, max_1y_date, min_1y_date = None, None, None, None
            diff_max_1y_pct, diff_min_1y_pct = None, None
        else:
            max_1y, min_1y = df_1y['NAV'].max(), df_1y['NAV'].min()
            max_1y_date = df_1y.loc[df_1y['NAV'].idxmax(), 'æ—¥æœŸ']
            min_1y_date = df_1y.loc[df_1y['NAV'].idxmin(), 'æ—¥æœŸ']
            
            # è¨ˆç®—èˆ‡æ¥µå€¼çš„å·®è·ç™¾åˆ†æ¯”
            diff_max_1y_pct = ((latest_nav - max_1y) / max_1y) * 100
            diff_min_1y_pct = ((latest_nav - min_1y) / min_1y) * 100

        return {
            "åŸºé‡‘åç¨±": fund_name,
            "æœ€æ–°åƒ¹æ ¼": latest_nav,
            "æœ€æ–°åƒ¹æ ¼æ—¥æœŸ": df['æ—¥æœŸ'].iloc[-1],
            "è¿‘ä¸€å¹´æœ€é«˜åƒ¹æ ¼": max_1y, "æœ€é«˜åƒ¹èˆ‡æœ€æ–°åƒ¹%": diff_max_1y_pct, "è¿‘ä¸€å¹´æœ€é«˜åƒ¹æ ¼æ—¥æœŸ": max_1y_date,
            "è¿‘ä¸€å¹´æœ€ä½åƒ¹æ ¼": min_1y, "æœ€ä½åƒ¹èˆ‡æœ€æ–°åƒ¹%": diff_min_1y_pct, "è¿‘ä¸€å¹´æœ€ä½åƒ¹æ ¼æ—¥æœŸ": min_1y_date,
            "æ­·å²æœ€é«˜åƒ¹æ ¼": hist_max, "æ­·å²æœ€é«˜åƒ¹æ ¼æ—¥æœŸ": hist_max_date,
            "æ­·å²æœ€ä½åƒ¹æ ¼": hist_min, "æ­·å²æœ€ä½åƒ¹æ ¼æ—¥æœŸ": hist_min_date,
            "åŸºé‡‘é€£çµ": url
        }

    @staticmethod
    def calculate_performance_metrics(df: pd.DataFrame, risk_free_rate: float) -> Dict[str, float]:
        """
        è¨ˆç®—é€²éšé¢¨éšªæŒ‡æ¨™ï¼šå¹´åŒ–æ¨™æº–å·®ã€å¤æ™®å€¼ã€æœ€å¤§å›æ’¤
        risk_free_rate: ç„¡é¢¨éšªåˆ©ç‡ (ä¾‹å¦‚ 4.0 ä»£è¡¨ 4%)
        """
        df = df.sort_values('æ—¥æœŸ')
        df['pct_change'] = df['NAV'].pct_change()
        returns = df['pct_change'].dropna()
        
        if returns.empty:
            return {"volatility": 0.0, "sharpe": 0.0, "annual_return": 0.0, "mdd": 0.0}

        # 1. å¹´åŒ–æ¨™æº–å·® (Volatility)
        volatility = FundAnalyzer._calculate_annualized_volatility(returns)
        
        # 2. å¹´åŒ–å ±é…¬ç‡ (CAGR)
        annual_return = FundAnalyzer._calculate_cagr(df)

        # 3. å¤æ™®å€¼ (Sharpe)
        rf_decimal = risk_free_rate / 100.0
        sharpe_ratio = (annual_return - rf_decimal) / volatility if volatility > 0 else 0

        # 4. æœ€å¤§å›æ’¤ (Max Drawdown)
        max_drawdown = FundAnalyzer._calculate_max_drawdown(df['NAV'])

        return {
            "volatility": volatility * 100,
            "sharpe": sharpe_ratio,
            "annual_return": annual_return * 100,
            "mdd": max_drawdown * 100
        }

    # --- å…§éƒ¨è¼”åŠ©è¨ˆç®—æ–¹æ³• (Refactored) ---
    @staticmethod
    def _calculate_annualized_volatility(returns: pd.Series) -> float:
        """è¨ˆç®—å¹´åŒ–æ¨™æº–å·®"""
        return returns.std() * np.sqrt(252)

    @staticmethod
    def _calculate_cagr(df: pd.DataFrame) -> float:
        """è¨ˆç®—å¹´åŒ–å ±é…¬ç‡ (CAGR)"""
        total_return = (df['NAV'].iloc[-1] / df['NAV'].iloc[0]) - 1
        days = (df['æ—¥æœŸ'].iloc[-1] - df['æ—¥æœŸ'].iloc[0]).days
        if days <= 0: return 0.0
        return (1 + total_return) ** (365 / days) - 1

    @staticmethod
    def _calculate_max_drawdown(prices: pd.Series) -> float:
        """è¨ˆç®—æœ€å¤§å›æ’¤"""
        rolling_max = prices.cummax()
        drawdown = (prices - rolling_max) / rolling_max
        return drawdown.min()

    @staticmethod
    def calculate_correlation_matrix(data_map: Dict[str, pd.DataFrame], selected_keys: List[str], start_date: datetime) -> pd.DataFrame:
        """è¨ˆç®—å¤šè³‡ç”¢çš„ç›¸é—œä¿‚æ•¸çŸ©é™£"""
        # 1. æº–å‚™åˆä½µç”¨çš„ DataFrame
        merged_df = pd.DataFrame()
        
        for key in selected_keys:
            if key in data_map:
                df = data_map[key].copy()
                df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
                # ç¯©é¸æ—¥æœŸ
                df = df[df['æ—¥æœŸ'] >= start_date]
                if not df.empty:
                    df = df.set_index('æ—¥æœŸ')
                    # å–å‡ºåç¨±ä½œç‚ºæ¬„ä½å
                    col_name = df['åŸºé‡‘åç¨±'].iloc[0]
                    merged_df[col_name] = df['NAV']
        
        # 2. è¨ˆç®— pct_change ä¸¦è¨ˆç®—ç›¸é—œä¿‚æ•¸
        if merged_df.empty:
            return pd.DataFrame()
            
        # ä½¿ç”¨æ—¥å ±é…¬ç‡ä¾†è¨ˆç®—ç›¸é—œæ€§æ‰æº–ç¢ºï¼Œä¸èƒ½ç”¨åƒ¹æ ¼ç›´æ¥ç®—
        returns_df = merged_df.pct_change().dropna()
        return returns_df.corr()

    @staticmethod
    def analyze_all(data_map: Dict[str, pd.DataFrame]) -> pd.DataFrame:
        summary_list = []
        for df in data_map.values():
            summary_list.append(FundAnalyzer.analyze_single(df))
        return pd.DataFrame(summary_list)


class BacktestEngine:
    """å›æ¸¬è¨ˆç®—å¼•æ“"""
    
    @staticmethod
    def calculate_lump_sum(df: pd.DataFrame, invest_date: datetime, amount: float):
        """è¨ˆç®—å–®ç­†æŠ•å…¥å›å ±"""
        df = df.sort_values('æ—¥æœŸ').reset_index(drop=True)
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        
        start_row = df[df['æ—¥æœŸ'] >= invest_date].head(1)
        if start_row.empty: return None, "é¸å®šæ—¥æœŸç„¡æœ‰æ•ˆæ•¸æ“š"
        
        start_price = start_row['NAV'].values[0]
        real_start_date = start_row['æ—¥æœŸ'].dt.date.values[0]
        
        end_price = df['NAV'].iloc[-1]
        end_date = df['æ—¥æœŸ'].iloc[-1].date()
        
        final_value = (amount / start_price) * end_price
        roi = ((final_value - amount) / amount) * 100
        
        return {
            "type": "å–®ç­†æŠ•å…¥", "real_start_date": real_start_date, "end_date": end_date,
            "start_price": start_price, "end_price": end_price,
            "invested_capital": amount, "final_value": final_value, "roi": roi
        }, None

    @staticmethod
    def calculate_dca(df: pd.DataFrame, start_date: datetime, monthly_day: int, amount: float):
        """è¨ˆç®—å®šæœŸå®šé¡å›å ±"""
        df = df.sort_values('æ—¥æœŸ').reset_index(drop=True)
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        
        start_date = pd.to_datetime(start_date)
        records, total_units, total_invested = [], 0, 0
        data_end_date = df['æ—¥æœŸ'].iloc[-1]
        current_month_first = start_date.replace(day=1)
        
        while current_month_first <= data_end_date:
            try:
                target_date = current_month_first.replace(day=monthly_day)
            except ValueError:
                target_date = (current_month_first + relativedelta(months=1)) - timedelta(days=1)
            
            if target_date >= start_date and target_date <= data_end_date:
                trade_row = df[df['æ—¥æœŸ'] >= target_date].head(1)
                if not trade_row.empty:
                    price, trade_date = trade_row['NAV'].values[0], trade_row['æ—¥æœŸ'].dt.date.values[0]
                    if not records or records[-1]['date'] != trade_date:
                        units = amount / price
                        total_units += units
                        total_invested += amount
                        records.append({'date': trade_date, 'price': price, 'units': units, 'cumulative_invested': total_invested})
            
            current_month_first += relativedelta(months=1)
            
        if total_invested == 0: return None, "åœ¨æ­¤æœŸé–“å…§ç„¡æœ‰æ•ˆç´€éŒ„"
        
        final_value = total_units * df['NAV'].iloc[-1]
        roi = ((final_value - total_invested) / total_invested) * 100
        return {
            "type": "å®šæœŸå®šé¡", "start_date": records[0]['date'], "end_date": data_end_date.date(),
            "total_invested": total_invested, "final_value": final_value, "roi": roi,
            "deduct_count": len(records), "records": pd.DataFrame(records)
        }, None

    @staticmethod
    def generate_quick_summary(df: pd.DataFrame):
        """ç”¢ç”Ÿå¿«é€Ÿå›æ¸¬ç¸½è¡¨"""
        periods = {
            "è¿‘ 1 æœˆ": relativedelta(months=1), "è¿‘ 3 æœˆ": relativedelta(months=3),
            "è¿‘ 6 æœˆ": relativedelta(months=6), "è¿‘ 1 å¹´": relativedelta(years=1),
            "è¿‘ 3 å¹´": relativedelta(years=3), "è¿‘ 5 å¹´": relativedelta(years=5),
            "è¿‘ 10 å¹´": relativedelta(years=10)
        }
        results, today = [], datetime.now()
        for name, delta in periods.items():
            start_date = today - delta
            rl, el = BacktestEngine.calculate_lump_sum(df, start_date, 100000)
            rd, ed = BacktestEngine.calculate_dca(df, start_date, 5, 5000)
            results.append({
                "é€±æœŸ": name,
                "å–®ç­†å ±é…¬ç‡ (%)": f"{rl['roi']:.2f}" if not el else "-",
                "å®šæœŸå®šé¡å ±é…¬ç‡ (%)": f"{rd['roi']:.2f}" if not ed else "-"
            })
        return pd.DataFrame(results)

# ==========================================
# 4. è¼¸å‡ºèˆ‡è¦–è¦ºåŒ–å±¤ (Output & Visualization Layer)
# ==========================================
class ExcelReport:
    """è² è²¬ç”Ÿæˆ Excel å ±è¡¨"""
    @staticmethod
    def create_excel_bytes(summary_df: pd.DataFrame) -> bytes:
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df_disp = summary_df.drop(columns=['åŸºé‡‘é€£çµ'])
            df_disp.to_excel(writer, index=False, header=False, sheet_name='Summary', startrow=1)
            workbook, worksheet = writer.book, writer.sheets['Summary']
            ExcelReport._apply_styles(workbook, worksheet, df_disp, summary_df)
            ExcelReport._set_columns_width(df_disp, worksheet)
            worksheet.freeze_panes(1, 0)
        return output.getvalue()

    @staticmethod
    def _apply_styles(wb, ws, df, orig):
        fmt = {
            'header': wb.add_format({'bold': True, 'font_name': 'Microsoft JhengHei', 'bg_color': '#DCE6F1', 'align': 'center', 'border': 1}),
            'text': wb.add_format({'font_name': 'Microsoft JhengHei', 'border': 1}),
            'num': wb.add_format({'font_name': 'Microsoft JhengHei', 'border': 1, 'num_format': '#,##0.00'}),
            'link': wb.add_format({'font_color': 'blue', 'underline': 1, 'font_name': 'Microsoft JhengHei', 'border': 1}),
            'date': wb.add_format({'num_format': 'yyyy-mm-dd', 'font_name': 'Microsoft JhengHei', 'border': 1})
        }
        for c, v in enumerate(df.columns): ws.write(0, c, v, fmt['header'])
        date_cols = [i for i, c in enumerate(df.columns) if 'æ—¥æœŸ' in str(c)]
        
        for i in range(len(df)):
            ws.write_url(i+1, 0, orig.iloc[i]['åŸºé‡‘é€£çµ'], fmt['link'], string=df.iat[i, 0])
            for j in range(1, len(df.columns)):
                v = df.iat[i, j]
                if j in date_cols and pd.notna(v): ws.write_datetime(i+1, j, pd.to_datetime(v), fmt['date'])
                elif isinstance(v, (int, float)): ws.write_number(i+1, j, v, fmt['num'])
                else: ws.write(i+1, j, str(v), fmt['text'])

    @staticmethod
    def _set_columns_width(df, ws):
        for i, col in enumerate(df.columns):
            ml = max(df[col].astype(str).map(lambda x: len(x.encode('utf-8'))).max(), len(str(col).encode('utf-8')))
            ws.set_column(i, i, min(max(ml * 0.8, 10), 50))

class ChartManager:
    """è² è²¬ç¹ªè£½ Plotly åœ–è¡¨"""
    
    @staticmethod
    def _filter_data(all_data, keys, tr_key):
        """å…±ç”¨æ•¸æ“šéæ¿¾é‚è¼¯"""
        start_date = Config.get_start_date(tr_key)
        filtered = {}
        for k in keys:
            if k in all_data:
                df = all_data[k].copy().sort_values('æ—¥æœŸ')
                df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
                df = df[df['æ—¥æœŸ'] >= start_date]
                if not df.empty:
                    filtered[k] = df
        return filtered

    @staticmethod
    def plot_dual_axis_trends(all_data: Dict[str, pd.DataFrame], selected_keys: List[str], time_range_key: str):
        """ç¹ªè£½é›™Yè»¸åƒ¹æ ¼èµ°å‹¢æ¯”è¼ƒåœ–"""
        if not selected_keys: return
        
        filtered_data = ChartManager._filter_data(all_data, selected_keys, time_range_key)
        if not filtered_data:
            st.warning("é¸å®šå€é–“å…§ç„¡æ•¸æ“š")
            return

        plot_dfs = []
        global_min, global_max = 1.0, 1.0
        
        for k, df in filtered_data.items():
            sp = df['NAV'].iloc[0]
            ratios = df['NAV'] / sp
            global_min = min(global_min, ratios.min())
            global_max = max(global_max, ratios.max())
            plot_dfs.append({"data": df, "name": str(df['åŸºé‡‘åç¨±'].iloc[0]), "sp": sp})

        pad = (global_max - global_min) * 0.05
        y_range_min, y_range_max = global_min - pad, global_max + pad

        fig = go.Figure()
        # ç¬¬ä¸€æ¢ç·š
        d1 = plot_dfs[0]
        fig.add_trace(go.Scatter(x=d1["data"]['æ—¥æœŸ'], y=d1["data"]['NAV'], name=d1["name"], yaxis='y', hovertemplate='%{y:,.2f}'))
        y1_range = [d1["sp"] * y_range_min, d1["sp"] * y_range_max]
        
        layout_update = {
            'title': f'è³‡ç”¢åƒ¹æ ¼èµ°å‹¢æ¯”è¼ƒ ({time_range_key})',
            'xaxis': dict(title='æ—¥æœŸ'), 'hovermode': 'x unified', 'legend': dict(orientation="h", y=1.1),
            'yaxis': dict(title=d1["name"], range=y1_range, tickformat=',.2f', title_font=dict(color='#1f77b4'), tickfont=dict(color='#1f77b4'))
        }

        # ç¬¬äºŒæ¢ç·š (å¦‚æœæœ‰)
        if len(plot_dfs) > 1:
            d2 = plot_dfs[1]
            fig.add_trace(go.Scatter(x=d2["data"]['æ—¥æœŸ'], y=d2["data"]['NAV'], name=d2["name"], yaxis='y2', hovertemplate='%{y:,.2f}'))
            y2_range = [d2["sp"] * y_range_min, d2["sp"] * y_range_max]
            layout_update['yaxis2'] = dict(
                title=d2["name"], overlaying='y', side='right', range=y2_range, tickformat=',.2f',
                title_font=dict(color='#ff7f0e'), tickfont=dict(color='#ff7f0e')
            )

        fig.update_layout(**layout_update)
        st.plotly_chart(fig, use_container_width=True)

    @staticmethod
    def plot_investment_growth(all_data: Dict[str, pd.DataFrame], selected_keys: List[str], time_range_key: str):
        """ç¹ªè£½ 100 è¬æŠ•è³‡å¢å€¼åœ–"""
        if not selected_keys: return
        
        filtered_data = ChartManager._filter_data(all_data, selected_keys, time_range_key)
        if not filtered_data: return

        fig = go.Figure()
        initial_capital = 1_000_000
        
        for k, df in filtered_data.items():
            sp = df['NAV'].iloc[0]
            growth = (df['NAV'] / sp) * initial_capital
            fig.add_trace(go.Scatter(
                x=df['æ—¥æœŸ'], y=growth, name=str(df['åŸºé‡‘åç¨±'].iloc[0]),
                hovertemplate='%{y:,.0f}'
            ))

        fig.update_layout(
            title=f'100 è¬è³‡ç”¢å¢å€¼æ¨¡æ“¬ ({time_range_key})',
            xaxis=dict(title='æ—¥æœŸ'),
            yaxis=dict(title='è³‡ç”¢ç¸½å€¼ (å…ƒ)', tickformat=',.0f'),
            hovermode='x unified', legend=dict(orientation="h", y=1.1)
        )
        st.plotly_chart(fig, use_container_width=True)

    @staticmethod
    def plot_correlation_heatmap(all_data: Dict[str, pd.DataFrame], selected_keys: List[str], time_range_key: str):
        """ã€æ–°å¢ã€‘ç¹ªè£½ç›¸é—œæ€§ç†±åŠ›åœ–"""
        if len(selected_keys) < 2:
            st.info("è«‹è‡³å°‘é¸æ“‡ 2 å€‹æ¨™çš„ä»¥é¡¯ç¤ºç›¸é—œæ€§çŸ©é™£ã€‚")
            return

        start_date = Config.get_start_date(time_range_key)
        corr_matrix = FundAnalyzer.calculate_correlation_matrix(all_data, selected_keys, start_date)
        
        if corr_matrix.empty:
            st.warning("é¸å®šå€é–“å…§ç„¡å…±åŒäº¤æ˜“æ•¸æ“šï¼Œç„¡æ³•è¨ˆç®—ç›¸é—œæ€§ã€‚")
            return

        fig = px.imshow(
            corr_matrix, 
            text_auto=".2f", 
            aspect="auto",
            color_continuous_scale="RdBu_r", # ç´…è—é…è‰² (ç´…=æ­£ç›¸é—œ, è—=è² ç›¸é—œ)
            zmin=-1, zmax=1,
            title=f"è³‡ç”¢ç›¸é—œæ€§çŸ©é™£ ({time_range_key})"
        )
        st.plotly_chart(fig, use_container_width=True)

# ==========================================
# 5. æ‡‰ç”¨ç¨‹å¼é‚è¼¯ (Application Logic)
# ==========================================

@st.cache_data(ttl=3600, show_spinner="æ­£åœ¨è¼‰å…¥æ•¸æ“š...")
def load_data_with_cache(target_markets: Dict[str, str], fund_ids: List[str]) -> Dict[str, pd.DataFrame]:
    """å¿«å–è³‡æ–™è¼‰å…¥å‡½å¼"""
    all_data = {}
    if target_markets: all_data.update(MarketScraper().fetch_all(target_markets))
    if fund_ids: all_data.update(FundScraper().fetch_all(fund_ids))
    return all_data

def render_sidebar() -> Tuple[Dict[str, str], List[str]]:
    """æ¸²æŸ“å´é‚Šæ¬„ä¸¦å›å‚³ä½¿ç”¨è€…çš„é¸æ“‡"""
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®šé¢æ¿")
        with st.expander("ğŸŒ å…¨çƒå¸‚å ´æŒ‡æ¨™", expanded=True):
            selected_market_names = st.multiselect(
                "é¸æ“‡æŒ‡æ¨™", options=list(Config.MARKET_TICKERS.keys()), default=list(Config.MARKET_TICKERS.keys())
            )
            target_markets = {n: Config.MARKET_TICKERS[n] for n in selected_market_names}
        with st.expander("ğŸ¦ åœ‹æ³°åŸºé‡‘æ¸…å–®", expanded=True):
            fund_input_str = st.text_area("åŸºé‡‘ä»£è™Ÿ", value=",\n".join(Config.DEFAULT_FUND_IDS_LIST), height=300)
            fund_ids = [x.strip() for x in fund_input_str.replace("\n", ",").split(",") if x.strip()]
    return target_markets, fund_ids

def render_tab_overview(all_data: Dict[str, pd.DataFrame]):
    """æ¸²æŸ“åˆ†é  1ï¼šå ±è¡¨ç¸½è¦½"""
    summary_df = FundAnalyzer.analyze_all(all_data)
    st.success(f"âœ… å®Œæˆï¼å…±åˆ†æ {len(summary_df)} ç­†æ¨™çš„")
    st.dataframe(summary_df)
    excel_data = ExcelReport.create_excel_bytes(summary_df)
    st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel å ±è¡¨", excel_data, f"Global_Report_{datetime.now().strftime('%Y%m%d')}.xlsx")

def render_tab_chart(all_data: Dict[str, pd.DataFrame], options_map: Dict[str, str]):
    """æ¸²æŸ“åˆ†é  2ï¼šè¶¨å‹¢èˆ‡é¢¨éšªåˆ†æ"""
    st.subheader("è³‡ç”¢åƒ¹æ ¼èˆ‡é¢¨éšªåˆ†æ")
    
    # æ§åˆ¶é …
    time_range = st.radio("å€é–“:", options=list(Config.TIME_RANGES.keys()), index=3, horizontal=True)
    selected_labels = st.multiselect("é¸æ“‡è³‡ç”¢ (å»ºè­° 2-5 å€‹):", options=list(options_map.keys()), max_selections=None) # è§£é™¤æ•¸é‡é™åˆ¶ä»¥ä¾¿è§€çœ‹ç›¸é—œæ€§
    selected_keys = [options_map[l] for l in selected_labels]
    
    # ç²å–ç„¡é¢¨éšªåˆ©ç‡ (^TNX)
    rf_rate = 4.0
    tnx_key = "ç¾åœ‹ 10 å¹´æœŸå…¬å‚µæ®–åˆ©ç‡"
    if tnx_key in all_data and not all_data[tnx_key].empty:
        rf_rate = all_data[tnx_key]['NAV'].iloc[-1]
    
    if selected_keys:
        # --- 1. é¢¨éšªæŒ‡æ¨™ ---
        st.markdown("##### ğŸ“Š é¢¨éšªèˆ‡å ±é…¬æŒ‡æ¨™ (å€é–“å¹´åŒ–)")
        
        # é™åˆ¶æŒ‡æ¨™é¡¯ç¤ºæ•¸é‡ï¼Œé¿å…ç‰ˆé¢éæ“ 
        display_limit = 4
        display_keys = selected_keys[:display_limit]
        cols = st.columns(max(len(display_keys), 1))
        
        filtered_data = ChartManager._filter_data(all_data, display_keys, time_range)
        
        for idx, key in enumerate(display_keys):
            if key in filtered_data:
                df_period = filtered_data[key]
                metrics = FundAnalyzer.calculate_performance_metrics(df_period, rf_rate)
                name = df_period['åŸºé‡‘åç¨±'].iloc[0]
                
                with cols[idx]:
                    st.markdown(f"**{name}**")
                    c1, c2, c3 = st.columns(3)
                    c1.metric("Sharpe", f"{metrics['sharpe']:.2f}")
                    c2.metric("æ³¢å‹•åº¦", f"{metrics['volatility']:.1f}%")
                    c3.metric("Max Drawdown", f"{metrics['mdd']:.1f}%", delta_color="inverse")
        
        if len(selected_keys) > display_limit:
            st.caption(f"* åƒ…é¡¯ç¤ºå‰ {display_limit} ç­†è³‡ç”¢çš„è©³ç´°æŒ‡æ¨™ï¼Œæ›´å¤šè³‡ç”¢è«‹è‡³ä¸‹æ–¹åœ–è¡¨æŸ¥çœ‹ã€‚")

        st.caption(f"* ç„¡é¢¨éšªåˆ©ç‡æ¡ç”¨ã€ç¾åœ‹ 10 å¹´æœŸå…¬å‚µæ®–åˆ©ç‡ã€‘ï¼š{rf_rate:.2f}%")
        st.divider()
        
        # --- 2. ç›¸é—œæ€§çŸ©é™£ (New) ---
        with st.expander("ğŸ”— è³‡ç”¢ç›¸é—œæ€§çŸ©é™£ (Correlation Heatmap)", expanded=True):
            ChartManager.plot_correlation_heatmap(all_data, selected_keys, time_range)
        
        st.divider()

        # --- 3. åœ–è¡¨ ---
        # ç‚ºäº†é›™è»¸åœ–è¡¨çš„å¯è®€æ€§ï¼Œæˆ‘å€‘åªå–å‰å…©å€‹
        plot_keys_dual = selected_keys[:2]
        ChartManager.plot_dual_axis_trends(all_data, plot_keys_dual, time_range)
        if len(selected_keys) > 2:
            st.caption("* é›™è»¸èµ°å‹¢åœ–åƒ…é¡¯ç¤ºå‰ 2 å€‹é¸å®šé …ç›®ï¼Œä»¥ç¢ºä¿å¯è®€æ€§ã€‚")
            
        st.divider()
        ChartManager.plot_investment_growth(all_data, selected_keys, time_range)

def render_tab_backtest(all_data: Dict[str, pd.DataFrame], options_map: Dict[str, str]):
    """æ¸²æŸ“åˆ†é  3ï¼šæŠ•è³‡å›æ¸¬"""
    st.subheader("ğŸ’° ç­–ç•¥å›æ¸¬")
    # åˆå§‹åŒ– Session State
    for key in ['calc_results_lump', 'calc_results_dca']:
        if key not in st.session_state: st.session_state[key] = None
            
    target_label = st.selectbox("æ¨™çš„:", list(options_map.keys()))
    if st.session_state.get('last_target') != target_label:
        st.session_state.update({'last_target': target_label, 'calc_results_lump': None, 'calc_results_dca': None})
    
    target_df = all_data.get(options_map[target_label])
    if target_df is not None:
        st.dataframe(BacktestEngine.generate_quick_summary(target_df), hide_index=True)
        col_lump, col_dca = st.columns(2)
        
        with col_lump:
            st.markdown("### 1ï¸âƒ£ å–®ç­†æŠ•å…¥")
            ld = st.date_input("è²·å…¥æ—¥", value=datetime.now()-relativedelta(years=1), max_value=datetime.now())
            la = st.number_input("æŠ•å…¥é‡‘é¡", value=1000000, step=100000)
            if st.button("è¨ˆç®—å–®ç­†"): 
                st.session_state['calc_results_lump'], _ = BacktestEngine.calculate_lump_sum(target_df, pd.to_datetime(ld), la)
            
            if st.session_state['calc_results_lump']:
                res = st.session_state['calc_results_lump']
                c = "green" if res['roi'] >= 0 else "red"
                st.markdown(f"å¸‚å€¼: **{res['final_value']:,.0f}** (ROI: <span style='color:{c}'>{res['roi']:.2f}%</span>)", unsafe_allow_html=True)

        with col_dca:
            st.markdown("### 2ï¸âƒ£ å®šæœŸå®šé¡")
            ds = st.date_input("é–‹å§‹æ—¥", value=datetime.now()-relativedelta(years=1), max_value=datetime.now())
            dd, da = st.number_input("æ‰£æ¬¾æ—¥", 1, 31, 5), st.number_input("æ¯æœŸé‡‘é¡", value=10000, step=1000)
            if st.button("è¨ˆç®— DCA"): 
                st.session_state['calc_results_dca'], _ = BacktestEngine.calculate_dca(target_df, pd.to_datetime(ds), dd, da)
            
            if st.session_state['calc_results_dca']:
                res = st.session_state['calc_results_dca']
                c = "green" if res['roi'] >= 0 else "red"
                st.markdown(f"å¸‚å€¼: **{res['final_value']:,.0f}** (ROI: <span style='color:{c}'>{res['roi']:.2f}%</span>)", unsafe_allow_html=True)
                with st.expander("è©³ç´°ç´€éŒ„"): st.dataframe(res['records'], hide_index=True)

def main():
    st.title("ğŸ“Š å…¨çƒå¸‚å ´èˆ‡åŸºé‡‘æ·¨å€¼æˆ°æƒ…å®¤")
    target_markets, fund_ids = render_sidebar()

    if st.button("ğŸš€ é–‹å§‹/æ›´æ–° åˆ†æ", type="primary"):
        st.session_state['has_run'] = True

    if st.session_state.get('has_run'):
        all_data = load_data_with_cache(target_markets, fund_ids)
        if not all_data: return st.error("âŒ æœªå–å¾—è³‡æ–™")

        options_map = {f"{df['åŸºé‡‘åç¨±'].iloc[0]} ({k})" if df['åŸºé‡‘åç¨±'].iloc[0] != k else k: k for k, df in all_data.items() if not df.empty}
        
        t1, t2, t3 = st.tabs(["ğŸ“‹ å ±è¡¨ç¸½è¦½", "ğŸ“ˆ è³‡ç”¢è¶¨å‹¢æ¯”è¼ƒ", "ğŸ’° æŠ•è³‡ç­–ç•¥å›æ¸¬"])
        with t1: render_tab_overview(all_data)
        with t2: render_tab_chart(all_data, options_map)
        with t3: render_tab_backtest(all_data, options_map)

if __name__ == "__main__":
    main()